{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "cpu\n",
      "[1  1] loss: 0.0025\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20924/365155095.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20924/365155095.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;31m#print every 1000th time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms \n",
    "import torchvision \n",
    "import torch\n",
    "import numpy as np \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class baseBlock(torch.nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self,input_planes,planes,stride=1,dim_change=None):\n",
    "        super(baseBlock,self).__init__()\n",
    "        #declare convolutional layers with batch norms\n",
    "        self.conv1 = torch.nn.Conv2d(input_planes,planes,stride=stride,kernel_size=3,padding=1)\n",
    "        self.bn1   = torch.nn.BatchNorm2d(planes)\n",
    "        self.conv2 = torch.nn.Conv2d(planes,planes,stride=1,kernel_size=3,padding=1)\n",
    "        self.bn2   = torch.nn.BatchNorm2d(planes)\n",
    "        self.dim_change = dim_change\n",
    "    def forward(self,x):\n",
    "        #Save the residue\n",
    "        res = x\n",
    "        output = F.relu(self.bn1(self.conv1(x)))\n",
    "        output = self.bn2(self.conv2(output))\n",
    "\n",
    "        if self.dim_change is not None:\n",
    "            res = self.dim_change(res)\n",
    "        \n",
    "        output += res\n",
    "        output = F.relu(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "class bottleNeck(torch.nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self,input_planes,planes,stride=1,dim_change=None):\n",
    "        super(bottleNeck,self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(input_planes,planes,kernel_size=1,stride=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(planes)\n",
    "        self.conv2 = torch.nn.Conv2d(planes,planes,kernel_size=3,stride=stride,padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(planes)\n",
    "        self.conv3 = torch.nn.Conv2d(planes,planes*self.expansion,kernel_size=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(planes*self.expansion)\n",
    "        self.dim_change = dim_change\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res = x\n",
    "        \n",
    "        output = F.relu(self.bn1(self.conv1(x)))\n",
    "        output = F.relu(self.bn2(self.conv2(output)))\n",
    "        output = self.bn3(self.conv3(output))\n",
    "\n",
    "        if self.dim_change is not None:\n",
    "            res = self.dim_change(res)\n",
    "        \n",
    "        output += res\n",
    "        output = F.relu(output)\n",
    "        return output\n",
    "\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self,block,num_layers,classes=10):\n",
    "        super(ResNet,self).__init__()\n",
    "        #according to research paper:\n",
    "        self.input_planes = 64\n",
    "        self.conv1 = torch.nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn1   = torch.nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._layer(block,64,num_layers[0],stride=1)\n",
    "        self.layer2 = self._layer(block,128,num_layers[1],stride=2)\n",
    "        self.layer3 = self._layer(block,256,num_layers[2],stride=2)\n",
    "        self.layer4 = self._layer(block,512,num_layers[3],stride=2)\n",
    "        self.averagePool = torch.nn.AvgPool2d(kernel_size=4,stride=1)\n",
    "        self.fc    =  torch.nn.Linear(512*block.expansion,classes)\n",
    "    \n",
    "    def _layer(self,block,planes,num_layers,stride=1):\n",
    "        dim_change = None\n",
    "        if stride!=1 or planes != self.input_planes*block.expansion:\n",
    "            dim_change = torch.nn.Sequential(torch.nn.Conv2d(self.input_planes,planes*block.expansion,kernel_size=1,stride=stride),\n",
    "                                             torch.nn.BatchNorm2d(planes*block.expansion))\n",
    "        netLayers =[]\n",
    "        netLayers.append(block(self.input_planes,planes,stride=stride,dim_change=dim_change))\n",
    "        self.input_planes = planes * block.expansion\n",
    "        for i in range(1,num_layers):\n",
    "            netLayers.append(block(self.input_planes,planes))\n",
    "            self.input_planes = planes * block.expansion\n",
    "        \n",
    "        return torch.nn.Sequential(*netLayers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = F.avg_pool2d(x,4)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "                                        \n",
    "\n",
    "def test():\n",
    "        #To convert data from PIL to tensor\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "        )\n",
    "\n",
    "    #Load train and test set:\n",
    "    train = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
    "    trainset = torch.utils.data.DataLoader(train,batch_size=128,shuffle=True)\n",
    "\n",
    "    test = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
    "    testset = torch.utils.data.DataLoader(test,batch_size=128,shuffle=False)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    #ResNet-18 \n",
    "    #net = ResNet(baseBlock,[2,2,2,2],10)\n",
    "\n",
    "    #ResNet-50\n",
    "    net =  ResNet(bottleNeck,[3,4,6,3])\n",
    "    net.to(device)\n",
    "    costFunc = torch.nn.CrossEntropyLoss()\n",
    "    optimizer =  torch.optim.SGD(net.parameters(),lr=0.02,momentum=0.9)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        closs = 0\n",
    "        for i,batch in enumerate(trainset,0):\n",
    "            data,output = batch\n",
    "            data,output = data.to(device),output.to(device)\n",
    "            prediction = net(data)\n",
    "            loss = costFunc(prediction,output)\n",
    "            closs = loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print every 1000th time\n",
    "            if i%100 == 0:\n",
    "                print('[%d  %d] loss: %.4f'% (epoch+1,i+1,closs/1000))\n",
    "                closs = 0\n",
    "        correctHits=0\n",
    "        total=0\n",
    "        for batches in testset:\n",
    "            data,output = batches\n",
    "            data,output = data.to(device),output.to(device)\n",
    "            prediction = net(data)\n",
    "            _,prediction = torch.max(prediction.data,1)  #returns max as well as its index\n",
    "            total += output.size(0)\n",
    "            correctHits += (prediction==output).sum().item()\n",
    "        print('Accuracy on epoch ',epoch+1,'= ',str((correctHits/total)*100))\n",
    "\n",
    "    correctHits=0\n",
    "    total=0\n",
    "    for batches in testset:\n",
    "        data,output = batches\n",
    "        data,output = data.to(device),output.to(device)\n",
    "        prediction = net(data)\n",
    "        _,prediction = torch.max(prediction.data,1)  #returns max as well as its index\n",
    "        total += output.size(0)\n",
    "        correctHits += (prediction==output).sum().item()\n",
    "    print('Accuracy = '+str((correctHits/total)*100))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
